The first thing I still don't understand is about rational agency. On pages 13â€“14, you mentioned a possible objection:

> "If Noi can pick herself out as one person among many people and can describe herself as distinct from descriptions of these other people, then that's good enough."

You then defended against this by suggesting that whoever raised this objection should reread Perry's paper. According to Perry, Noi would lack a rational basis for behavior at a normal human level. However, consider the example Antares provided:

- If Noi knows that Noi is in danger, Noi has no special reason to run away.

But can't Noi simply believe that Noi is important, in the same way we think of ourselves as important? If Noi has a natural impulse to benefit herself, wouldn't that count as a reason to run away? Additionally, Noi can perform many actions for herself, such as planning. When we watch movies, we think the main character should act in certain ways, and we might even plan for the character. I believe these actions don't necessarily require de se belief.[^1] If this is right, then Noi can do the same.

The second thing I still don't understand why Noi cannot have a negative mental state. Take a headache as an example. My premise is that Noi can have the belief, "There is no headache." The problem now is how to analyze this statement to make sense of it. I think there are at least two possible solutions.

The first solution is what I suggested in class. Noi can choose to become a solipsist, in which case the statement "there is no headache in the universe" would be true. Then, Noi can establish a mind-body relation: "Whenever there is no rabbit around Noi's body, there is no rabbit experience in the universe." If becoming a solipsist is what it takes for Noi to become a "normal person," this does not seem to be a significant trade-off.

The second solution does not require Noi to become a solipsist. My premise is that, when we have a negative mental state, we believe "there is no headache," and we automatically[^2] know that the domain is restricted to ourselves because mental states come with self-acquaintance. Noi, however, does not initially have any automatic knowledge about domain restriction.

In this case, Noi can leave the quantifier unrestricted and choose to become a solipsist, which brings us back to the first solution. Alternatively, Noi can learn from others that there is actually _some_ domain restriction to the quantifier applying to mental states. Since Noi lacks the concept of _I_, Noi will never fully understand why this restriction exists or what it entails.[^3] However, if Noi trusts others, Noi can simply accept that a restriction exists. Moreover, Noi can learn from others that mental states are limited within the physical boundaries of Noi's body. In this way, Noi can establish the mind-body relation: "Whenever there is no rabbit around Noi's body, there is no rabbit experience in the unknown domain, and this domain does not extend beyond Noi's body.


This is a test of mobile sync.

[^1]: It might be objected that, when we watch movies, what's happening on our mind is actually "If I were in that situation, what would I do?" Then this still relies on our sense of self. This may be right, but I still think Noi can plan or make decisions, in the same way computer programs (like ChatGPT) can plan or make decisions.
[^2]: Although my intuition aligns with the self-acquaintance view, it is possible to exclude self-acquaintance from this argument. It could be argued that we simply know the domain restriction without further explanation. More radically, one might argue that we only know the domain by learning language. In this case, it might follow that we were once all Nois.
[^3]: But can we _really_ understand this restriction without begging the question?
