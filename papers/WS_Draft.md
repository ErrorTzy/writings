---
documentclass: exam
title: Assignment
author: Scott Tang
mainfont: FreeSerif
CJKmainfont: Noto Serif CJK SC
mathfont: XITS Math
---

This paper is probably not a typical metaphysics paper. Although the main upshot is to establish fundamentality without magic, the kind of move I defend applies beyond metaphysics. At a very high level, the paper grapples with a central tension. On one hand, it seems all possible philosophical conclusion must ultimately rely on intuitive presuppositions. If so, then we cannot establish anything if we throw away all of our intuitions. On the other hand, many of our intuitions seem shaky, unreliable or contingent. The problem, then, is to figure out which part of our intuition cannot (or at least, should not) be thrown away. 

I frist argue this tension is somehow get ignored in the discussion of fundamentality. The consequence is that, the facts about fundamentality, though well-motivated, seems to be established by magic. Then I argue for a principle that basically says, we cannot throw away our rational agency. And I spend the rest of the paper exploring what follows from it. Mostly, I use it to establish the directness of fundamentality without magic. But I also included a consequence in ethics.

The starting point of this paper comes from the following question: *How much reality should we read off our linguistic features?*

**Clarification of this question**: This way of asking the question immediately requires clarification. First, it seems to suggest linguistic idealism. It doesn't. Reality certainly does not depend on our language in any way. 

We might have ways to understand reality without language, perhaps through perception or mysterious experiences. But, this is not how metaphysicians work. When we discuss reality in metaphysics, we inevitably rely on sophisticated language to explain reality. This has generated a long-standing worry in philosophy. Since medieval times, philosophers (e.g. nominalists) have been worrying that we might be confusing words with reality. They doubt whether metaphysics reveals reality or merely reveals some linguistic feature. Hence my question: when we try to talk about reality, which parts genuinely reflect how things are, and which parts are mere "shadows of language"?

Indeed, this question appears central to almost all metaphysical problems. For example, almost all natural languages have a subject-predicate structure. Should we then say, the world itself is constituted of objects and properties? Grammatically we have predicates like 'good' or 'bad'. Then should we read them off our language and say there are such properties in the world? The proposition $P$ may seem syntactically more primitive than $\neg \neg P$. Should we read this structure off our language and say the *fact* that $P$ is in some sense more fundamental than the *fact* that $\neg \neg P$? Quantum physics describes the world in terms of wave functions. Should we then interpret that reality as just a bunch of waves (or maybe, a huge, holistic wave)?

It obvious that not every linguistic feature reveals reality. Take the names "Superman" and "Clark Kent." We don't think there are really two distinct entities out there connected by a relation named "identity". This is non-trivial. Formally, one could construct a toy model $M = \langle D, I \rangle$ with $D = \{s, c\}$, $I(\text{'Superman'}) = s$, $I(\text{'Clark Kent'}) = c$ and $I(\text{'is'})= \{ \langle s,c \rangle, \langle c,s \rangle \}$. Such model would satisfy 'Superman is Clark Kent'. But intuitively we do not take such a model to capture reality because we think 'Superman' and 'Clark Kent' should refer to the same entity in the domain. 

This question is intended to bypass Amie Thomasson style argument that, adopting a language is easy, and thus ontology is easy. Ontology can't be that easy because it is not trivial to freely read reality off any language we like. And the explicit question of reality is intend to capture the heavyweight idea of what is "really" out there.

(**Types of answers to the question:** There is of course a spectrum of views. On one extreme, we can never read anything off language. Kantian idealism seems to be this kind of *never-ism*. They may say any structure or category comes from the built-in categories of our cognition. We are simply projecting them onto reality. So, we can never know anything about reality *in itself*.

On the opposite pole, the thinking is that we can always read reality off some of our linguistic feature. This *always-ism* is less a single view and more a collection of ideas. For example, the "structured fact" view says that $F(x)$ is the same *fact* as $G(y)$ if and only if the $F \equiv G$ and $x=y$. A direct consequence of this is would be that $P$ is a different fact from $\neg \neg P$, as the syntax shows. 

Of course, there are also *sometimes-ism* in between. Armstrong, for instance, argued that we should only read predicates as real universals when those predicates pick out a genuine similarity in the world.)

The way I've framed the question, i.e. how much reality we should read off our linguistic features, is a bit different from the standard story told in metametaphysics. I think the standard narrative, which I'll lay out in a moment, tends to miss something important. I take the familiar story told by ==Schaffer (2009)==, probably the most-cited paper in the field, as the orthodox version (though I'll be telling a bit differently).

**The standard story** 

It goes something like this: contemporary metaphysics began with the Quine-Carnap debate. After Quine arguably won the debate, his approach to metaphysics prevailed. For Quine, the main task of metaphysics is to figure out what indispensably exists. Whether numbers or electrons exist depends on whether we must quantify over them in our best theories. This methodology was extended to other topics. Lewis, in some sense, can be seen as following the Quinean methodology: Since our best account of modality requires quantifying over possible worlds, possible worlds are real. From there, other concepts can be analyzed. Causation is explained by counterfactuals, which are analyzed in terms of possible worlds. Modality de re can be reduced to modality de dicto, plus some pragmatic, context-sensitive similarities. The takeaway is that most problems in metaphysics can be solved by first figuring out what exists and then maybe add a dash of pragmatics.

But then, the neo-Carnapians entered the scene. I believe the most important the idea from the neo-Carnapians is that, the meaning of "exists" can vary.[^2] According to this view, when different people debate about what exists, they are speaking different languages. If their languages are equivalent, then this is a mere verbal dispute.

Imagine one side speaks A-language and the other speaks B-language. For any sentence uttered by A-speakers, B-speakers will have their respective interpretation the sentence, vice versa. If the interpretation from each side always agrees on the truth value, then there's no disagreement other than disagreement on language: the other side is just expressing the fact in a different way. If that's the case, then many debates about what exists are merely verbal.[^3]

The implication here is serious. If metaphysics is founded on questions of existence, but quantifier variance shows that there are many equally good meanings of "existence" and the debates are merely verbal, then metaphysics risks becoming a trivial field of study.

Meanwhile the Neo-Aristotelians also come into play. They also attack on the neo-Quineans. They argued that even if we had a complete list of what exists, we'd still be missing something important: what is most fundamental, and what grounds what. Schaffer, for instance, argues that questions about existence are trivial. He says that of fictional characters and abstract objects trivially exist. The real, interesting question is about what grounds their existence. This shift in focus from existence to fundamentality has been the dominant trend in metaphysics for the past twenty years or so.

**The problem with the standard story**

Here's the problem. From the neo-Aristotelian perspective, this makes them look like the next logical step. In this view, the neo-Carnapians performed a useful, but purely *negative*, task by showing the flaws in the neo-Quinean focus on existence. With that groundwork laid, the neo-Aristotelians can then step in to offer a *positive* new project, turning the page on the neo-Quine-Carnap debate and building something new around concepts like grounding and fundamentality.

As a result of this framing, the standard story tends to sideline the neo-Carnapians. This isn't to say they're completely ignored, of course; people like Sider, Schaffer, and Bennett certainly take them seriously. Rather, the problem is that the standard story implies the neo-Carnapian critique is *only* about existence. And if that's the case, then the neo-Aristotelians, with their new focus, can safely disregard it. 

But this is surely not the case. The neo-Carnapian argument, on a high level, is about semantic variance. Therefore, it applies to any theory as long as the theory allows semantic variance. 

In order to see this more clearly, let's return to the question I framed at the start: *How much reality should we read off our linguistic features?*

**For the neo-Quineans**, the answer is *sometimes-ism about existence*. We need to paraphrase our ordinary language and scientific theories. While the exact rules for this paraphrasing are messy, but idea is to create a language that maximizes pragmatic virtues like simplicity, elegance, and explanatory power. It is from this idealized, paraphrased language that we are meant to read entities off the things being quantied over.

**For the neo-Carnapians**, the most plausible answer is *a general form of always-ism*: we can always freely read reality off our language. When another party, say John, uses a different yet equivalent language, there's nothing wrong with John, nor is there anything wrong with us. First, we can interpret both sides as speaking the truth, so there's no disagreement about facts. Second, from our point of view, there's nothing wrong with "John's way of thinking" because his resulting beliefs are also true. Here's why: if a sentence $S$ is true in language $L_{John}$​, then it is true for John to believe that $S$ *under the guise of* $L_{John}$.[^4] By the same token, from John's point of view, there's nothing wrong with us either, whether in terms of truth or in terms of beliefs.

This "under the guise of" is motivated by the distinction between propositions and facts. (What I mean by 'proposition' here is the objects of our beliefs, and what I mean by 'fact' is the thing in the world that makes a sentence true.) For example, "Superman can fly" and "Clark Kent can fly" are the same fact, but they are different propositions: one might believe the former but not the latter. One way to explain this is to say that someone believes of $x$ *under the guise* of 'Superman', that $x$ can fly, while not believing $x$ under the guise of 'Clark Kent' that $x$ can fly.

By the same token, neo-Carnapians suggest we can see different linguistic frameworks as different "guises" for understanding the world. If there are equivalent languages can serve as equally good guises, there are many different ways to structure our knowledge of reality. Each of these guises constitutes genuine, true knowledge. This move allows neo-Carnapians to embrace a form of realism, distancing themselves from an anti-realist never-ism.[^1]

**For the neo-Aristotelians**, it seems they are holding *sometimes-ism about explanation or definition*, and *always-ism about existence*. Everything we can talk about trivially exists, but it might be derivative or idea-dependent. And the way we establish this kind of dependency is through the structure of definition or explanation (==citation to Fine's essence and modality, guide to ground, and Schaffer's work==).

The essential feature of definitions (and explanations) is that they are inherently *asymmetric*: nothing can define itself, and if $A$ is defined by $B$, then $B$ cannot be defined by $A$. However, this only applies to "real definitions," not "nominal definitions." For example, we may nominally define "A is on the left side of B" by "B is on the right side of A," and define "B is on the right side of A" by "A is on the left side of B." In fact, this kind of circularity probably appears occasionally when terms are defined in the dictionary.

Given this distinction, we cannot say that any definition in our language establishes fundamentality. Only the "real" ones count. The same principle applies to explanation. Although grounding relations are explanatory, they are not explanation itself. Explanation is famously context-sensitive. It depends on things such as what we're emphasizing, and what interests our audience. Grounding relations, by contrast, are intended to be worldly, objective, and context-independent. Since they are separate, only "real" explanation can establish fundamentality. This leads neo-Aristotelians to embrace *sometimes-ism* about explanation or definition.

Now we can clearly see the issue. Neo-Carnapians are arguing for a general form of *always-ism*, which would naturally includes the *always-ism about explanation or definition*. The pressure that the neo-Carnapian argument would put on the neo-Aristotelians' *sometimes-ism* is that, what makes some definition or explanation privileged so that they get to establish fundamentality, but the other doesn't? 

I will later defend sometimes-ism against always-ism, but for now I will put on the hat of neo-Carnapians and explain why the neo-Aristotelians did not give a satisfying answer.

Let me start with a way to establish the privilege of definition with a familiar concept: naturalness. This notion is famously introduced by Lewis (==Citation a new theory of universals==), but it was generally restricted to properties. But it was Sider who attempt to use this to establish fundamentality (==Citation writing the book of the world==). 

More natural, less natural
Essence
Built, building
Non-logical circle


- **The principle of sanity**: For someone who is capable of philosophical reflection, it is impossible to genuinely believe oneself to not be a rational agent.

**Clarification for this principle**: This principle also applies to acceptance (i.e. It is impossible for someone to accept oneself to not be a rational agent), but I will focus on belief in the rest of the paper unless specified otherwise. Anyway, the upshot is, it is impossible for us to really adopt a theory that eliminates rational agency.

Here, "philosophical reflection" roughly refers to activities such as examining and revising one's beliefs, analyzing arguments, and choosing between competing theories. The condition "for a person capable of philosophical reflection" is to rule out certain exotic counterexamples. For instance, someone who has been so thoroughly brainwashed that their only possible belief is "I am not a rational agent" would not qualify as a counterexample. I assume all readers who have already made it here are automatically capable of philsosophical reflection. Similarly, saying "genuinely believe" is to rule out counterexamples from self-deception.

What I mean by "rational" here is a minimal sense of means-end coherence. For example, someone who wills their hand to rise but finds their leg going up instead would lack this coherence. Thus, even if this could somehow be a case of agency, it wouldn't be rational agency in the relevant sense.

The precise meaning of "rational agency", of course, is highly controversial and open to multiple acceptable interpretations. Consequently, this principle will have different variants depending on how one chooses to define the term. However, I contend that the *principle of sanity* is plausible under most, if not all, commonsensical interpretations.

For current purpose, it will suffice by adopting a minimal account of rational agency as *epistemic agency*. But I will add more to "rational agency" later in this paper. What I mean by "epistemic agency" here is not the kind of agency resisted by doxastic involuntarists. According to doxastic involuntarists, *direct* voluntary control over belief is not possible for us. But here, I use "epistemic agency" to refer to any sort of control over our beliefs, no matter how indirect. For example, we have the ability to choose to re-examine our beliefs and investigate new evidence. Doxastic involuntarists, like ==Hieronymi 2008==, also acknowledge that we possess this kind of indirect control. Therefore, it is uncontroversial that we have epistemic agency in the intended sense.

**Reasons for this principle**: This is more or less an axiom in this paper that I take to be self-evident. But I will still try to give some defense. 

First, implicitly, this is already a widely accepted principle. Aristotle appears to adopt this principle in Chapter 9 of _De Interpretatione_. There, he rejects the principle of bivalence due to our deliberation and action. He argues that, deliberation and action requires that, propositions about the future must be open (19a10). Then they cannot have a truth value now (19a26). Therefore the principle of bivalence is false. However, Aristotle's argument seems to epistemic instead of metaphysical. When he writes that "what will be has an origin both in deliberation and in action" (19a6-9), the plausible interpretation is that our *beliefs* about the future originate from these rational activities, not the future state of affairs itself. If so, his argument is best understood as follows: it is impossible for us to genuinely *believe* that the future is predetermined while simultaneously viewing ourselves as rational agents who deliberate. Therefore, by *the principle of sanity*, we cannot adopt the principle of bivalence.

There are also more contemporary cases.People seems to reject epiphenomenalism largely due to the reason that, if there's no mental causation, then it seems we wouldn't have any agency, which is insane. And I will argue later that, the motivation of a widely held metasemantics principle, *the Principle of Charity*, actually comes from of a stronger version of *the Principle of Sanity*. Therefore, in fact people have been implicitly using this principle.

Nonetheless, I will also try to sketch a direct defense. If the principle were false, then it would be possible for a creature to engage in philosophical reflection without believing itself to have rational agency. But philosophical reflection inherently requires making inferences and utilizing abstract concepts. Let's assume, as is widely held, that such complex thought requires language (or at least some language-like mentalese). Then, I argue in the following paragraph that using language for this purpose necessitates rational agency. Therefore this creature is impossible.

To use language requires intentionality. For example, a dinosaur that accidentally scratches the shape of the symbol "water" into the ground is not using language, because it does not use the symbol intentionally to represent something. Therefore, intentionality is necessary for language use. But to use representation intentionally for philosophical reflection just is to exercise the very sort of indirect, agential control over one's beliefs by potentially revising what one holds to be true. And we must be able, at least to some extent, to be aware of our own intentions. If we are aware of our intentions to some extent, we believe that we have such intentions. Thus, if we use language to engage in philosophical reflection, we must believe in epistemic agency.

I do not take this to be an invincible argument. Perhaps with some heavy argument, one may claim we can build a "philosophy machine" that can reflect on arguments and produce a philosophy paper while being completely non-agential. However, I believe it is quite obvious that rejecting the principle of sanity, plainly, is to be insane. Even if such a "philosophy machine" is possible, I still think no person should reject this principle, simply because we should not be insane.[^5]

There are obvious consequence for adopting this principle. Together with the following innocent principle that:

- **Ought Implies Can**: If it is impossible for us to believe that P, then it is not the case that we ought to believe that P.

It follows that *the Principle of Sanity* is incompatible with the traditional account of rationality: A belief is rational iff the reason to believe is truth-tracking. This is because the principle of sanity commits us to a belief we must hold (that we are rational agents), regardless of the evidence. Assume our epistemic norm is to hold only true beliefs, and scientists tell us that rational agency is just an illusion, then we would be obligated to believe that we are not rational agents. But according to the principle that *Ought Implies Can*, there is no such obligation.

Then immediately, one might object that if epistemic norms must be truth-tracking, then we should rationally reject *the Principle of Sanity* itself. However, what does it mean to "rationally reject" a principle? If doing so is an act of philosophical reflection, then, as argued earlier, the very act requires us to presuppose our own epistemic agency. Therefore, any attempt to "rationally reject" *the Principle of Sanity* is self-defeating, as the act of rejection presupposes the very rational agency the principle commands us to accept.

There is also an auxiliary argument that help me establish the metaphysical argument that I want to establish. According to the neo-Quinean view on metametaphysics, choosing between empirically-equivalent theories is a matter of comparing their pragmatic virtues. And usually, they were considering theoretic simplicity, elegance, etc. But what how could these pragmatic virtues more valuable than our rational agency? 

[^1]: However, this approach immediately faces a challenge. If I treat other people's languages as mere guises of reality, why shouldn't I treat my own language as a mere guise as well? Moreover, if my language is also a guise, then it seems we would collapse back into the anti-realist's never-ism. In order to answer this challenge, consider the following case. First, let's establish that the set of all well-formed English sentences, taken as finite strings, is countable. We can have a bijective function $f$ that maps every unique English sentence to a unique natural number. From this, we can construct a One-Word-Sentence language (OWS-language for short). In this language, each natural number (and thus each corresponding English sentence) is represented by a single, unique symbol (e.g., '∇', '§', 'Д'). Crucially, these symbols carry no internal syntactic information that mirrors the structure of the original English sentences. Now, imagine a creature that genuinely thinks in this OWS-language, not one that is secretly translating from English. Suppose that when we apply the inverse function, $f^{−1}$, to decode their one-word utterances, we find they agree with us on the truth value of every proposition. They even affirm the OWS-symbol that decodes to "There are objects and properties." Here is the problem. This creature's way of thinking is inconceivable to us. Given we stipulated that they think in OWS, it seems they cannot grasp the concepts of objects and properties. Yet, their statements, once translated, shows they think there are objects and properties. It is in cases like this that we must appeal to the "guised reality" view. We are forced to say that they believe there are objects and properties under the guise of their OWS-language, precisely because there is no way to understand their take on reality. In contrast, our own understanding is transparent. We don't normally need to take of our language as a "guise." We only appeal to this concept in specific cases of misalignment, such as with co-referring proper names like 'Superman' and 'Clark Kent.'
[^2]: I'm focusing on quantifier variance because I believe it's the most plausible and basic form of the neo-Carnapian position. ==Thomasson (2015 p. 70)== herself thinks her easy ontology doesn't depend on quantifier variance, but this is surely mistaken. Her project relies on the triviality of changing the extension of the predicate "exists". But this surely changes the meaning of the quantifier.
[^3]: There are a lot can be said in the dialectics around quantifier variance, like collapse argument, reference magnetism, etc. which I want to but cannot elaborate here. But I believe in the literature the general consensus has been that at least some version of quantifier variance is plausible and is (or at least should be) widely accepted
[^4]: As Hirsch has argued multiple times ==citation==, and even Sider seems to eventually agree (some citation), that there's nothing wrong with speaking and thinking in a language that is not isomorphic to the structure of reality
[^5]: In other words, I am in fact suggesting two different principles. The stronger version is what I explicitly laid down and inclined to stand with. But even if one somehow resisted it, my conclusion can still be established by the weaker version, i.e. if we are capable of philosophical reflection, then we should not believe we are not rational agents.