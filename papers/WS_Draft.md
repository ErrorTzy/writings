This paper is probably not a typical metaphysics paper. Although the main upshot is to establish fundamentality without magic, the kind of move I defend applies beyond metaphysics. At a very high level, the paper grapples with a central tension. On one hand, it seems all possible philosophical conclusion must ultimately rely on intuitive premises. ==Here, the word "premise" is used in a broad sense. For example, axiom schemas like modus ponens also count as premises in the relevant sense.== If so, then we cannot establish anything if we throw away all of our intuitions. On the other hand, many of our intuitions seem shaky, unreliable or contingent. The problem, then, is to figure out which part of our intuition cannot (or at least, should not) be thrown away. 

I frist argue this tension is somehow get ignored in the discussion of fundamentality. The consequence is that, the facts about fundamentality, though well-motivated, seems to be established by magic. Then I argue for a principle that basically says, we cannot throw away our rational agency. And I spend the rest of the paper exploring what follows from it. Mostly, I use it to establish the directness of fundamentality without magic. But I also included a consequence in ethics.

The starting point of this paper comes from the following question: *How much reality should we read off our linguistic features?*

**Clarification of this question**: This way of asking the question immediately requires clarification. First, it seems to suggest linguistic idealism. It doesn't. Reality certainly does not depend on our language in any way. 

We might have ways to understand reality without language, perhaps through perception or mysterious experiences. But, this is not how metaphysicians work. When we discuss reality in metaphysics, we inevitably rely on sophisticated language to explain reality. This has generated a long-standing worry in philosophy. Since medieval times, philosophers (e.g. nominalists) have been worrying that we might be confusing words with reality. They doubt whether metaphysics reveals reality or merely reveals some linguistic feature. Hence my question: when we try to talk about reality, which parts genuinely reflect how things are, and which parts are mere "shadows of language"?

Indeed, this question appears central to almost all metaphysical problems. For example, almost all natural languages have a subject-predicate structure. Should we then say, the world itself is constituted of objects and properties? Grammatically we have predicates like 'good' or 'bad'. Then should we read them off our language and say there are such properties in the world? The proposition $P$ may seem syntactically more primitive than $\neg \neg P$. Should we read this structure off our language and say the *fact* that $P$ is in some sense more fundamental than the *fact* that $\neg \neg P$? Quantum physics describes the world in terms of wave functions. Should we then interpret that reality as just a bunch of waves (or maybe, a huge, holistic wave)?

It obvious that not every linguistic feature reveals reality. Take the names "Superman" and "Clark Kent." We don't think there are really two distinct entities out there connected by a relation named "identity". This is non-trivial. Formally, one could construct a toy model $M = \langle D, I \rangle$ with $D = \{s, c\}$, $I(\text{'Superman'}) = s$, $I(\text{'Clark Kent'}) = c$ and $I(\text{'is'})= \{ \langle s,c \rangle, \langle c,s \rangle \}$. Such model would satisfy 'Superman is Clark Kent'. But intuitively we do not take such a model to capture reality because we think 'Superman' and 'Clark Kent' should refer to the same entity in the domain. 

This question is intended to bypass Amie Thomasson style argument that, adopting a language is easy, and thus ontology is easy. Ontology can't be that easy because it is not trivial to freely read reality off any language we like. And the explicit question of reality is intend to capture the heavyweight idea of what is "really" out there.

(**Types of answers to the question:** There is of course a spectrum of views. On one extreme, we can never read anything off language. Kantian idealism seems to be this kind of *never-ism*. They may say any structure or category comes from the built-in categories of our cognition. We are simply projecting them onto reality. So, we can never know anything about reality *in itself*.

On the opposite pole, the thinking is that we can always read reality off some of our linguistic feature. This *always-ism* is less a single view and more a collection of ideas. For example, the "structured fact" view says that $F(x)$ is the same *fact* as $G(y)$ if and only if the $F \equiv G$ and $x=y$. A direct consequence of this is would be that $P$ is a different fact from $\neg \neg P$, as the syntax shows. 

Of course, there are also *sometimes-ism* in between. Armstrong, for instance, argued that we should only read predicates as real universals when those predicates pick out a genuine similarity in the world.)

The way I've framed the question, i.e. how much reality we should read off our linguistic features, is a bit different from the standard story told in metametaphysics. I think the standard narrative, which I'll lay out in a moment, tends to miss something important. I take the familiar story told by ==Schaffer (2009)==, probably the most-cited paper in the field, as the orthodox version (though I'll be telling a bit differently).

**The standard story** 

It goes something like this: contemporary metaphysics began with the Quine-Carnap debate. After Quine arguably won the debate, his approach to metaphysics prevailed. For Quine, the main task of metaphysics is to figure out what indispensably exists. Whether numbers or electrons exist depends on whether we must quantify over them in our best theories. This methodology was extended to other topics. Lewis, in some sense, can be seen as following the Quinean methodology: Since our best account of modality requires quantifying over possible worlds, possible worlds are real. From there, other concepts can be analyzed. Causation is explained by counterfactuals, which are analyzed in terms of possible worlds. Modality de re can be reduced to modality de dicto, plus some pragmatic, context-sensitive similarities. The takeaway is that most problems in metaphysics can be solved by first figuring out what exists and then maybe add a dash of pragmatics.

But then, the neo-Carnapians entered the scene. I believe the most important the idea from the neo-Carnapians is that, the meaning of "exists" can vary. ==I'm focusing on quantifier variance because I believe it's the most plausible and basic form of the neo-Carnapian position. Thomasson (2015 p. 70) herself thinks her easy ontology doesn't depend on quantifier variance, but this is surely mistaken. Her project relies on the triviality of changing the extension of the predicate "exists". But this surely changes the meaning of the quantifier.== According to this view, when different people debate about what exists, they are speaking different languages. If their languages are equivalent, then this is a mere verbal dispute.

Imagine one side speaks A-language and the other speaks B-language. For any sentence uttered by A-speakers, B-speakers will have their respective interpretation the sentence, vice versa. If the interpretation from each side always agrees on the truth value, then there's no disagreement other than disagreement on language: the other side is just expressing the fact in a different way. ==Is there a tension to say there are structured facts? According to Hirsch's view, we are entitled to say the reality is structured, and other people are just expressing this structure in another way, so we are agreeing on the structure. So this IS the structure of the reality. Nothing more needs to be said. Then QV can accept structured facts. But this would lead to the fact that, there is no "absolute semantics" -- or what is the metaphysics of semantics? If I interprete L in L as I1, and in L' as I2, what really is the semantics of L?== If that's the case, then many debates about what exists are merely verbal. ==There are a lot can be said in the dialectics around quantifier variance, like collapse argument, reference magnetism, etc. which I want to but cannot elaborate here. But I believe in the literature the general consensus has been that at least some version of quantifier variance is plausible and widely accepted==

The implication here is serious. If metaphysics is founded on questions of existence, but quantifier variance shows that there are many equally good meanings of "existence" and the debates are merely verbal, then metaphysics risks becoming a trivial field of study.

Meanwhile the Neo-Aristotelians also come into play. They also attack on the neo-Quineans. They argued that even if we had a complete list of what exists, we'd still be missing something important: what is most fundamental, and what grounds what. Schaffer, for instance, argues that questions about existence are trivial. He says that of fictional characters and abstract objects trivially exist. The real, interesting question is about what grounds their existence. This shift in focus from existence to fundamentality has been the dominant trend in metaphysics for the past twenty years or so.

**The problem with the standard story**

Here's the problem. From the neo-Aristotelian perspective, this makes them look like the next logical step. In this view, the neo-Carnapians performed a useful, but purely *negative*, task by showing the flaws in the neo-Quinean focus on existence. With that groundwork laid, the neo-Aristotelians can then step in to offer a *positive* new project, turning the page on the neo-Quine-Carnap debate and building something new around concepts like grounding and fundamentality.

As a result of this framing, the standard story tends to sideline the neo-Carnapians. This isn't to say they're completely ignored, of course; people like Sider, Schaffer, and Bennett certainly take them seriously. Rather, the problem is that the standard story implies the neo-Carnapian critique is *only* about existence. And if that's the case, then the neo-Aristotelians, with their new focus, can safely disregard it. 

But this is surely not the case. The neo-Carnapian argument, on a high level, is about semantic variance. Therefore, it applies to any theory as long as the theory allows semantic variance. 

In order to see this more clearly, let's return to the question I framed at the start: *How much reality should we read off our linguistic features?*

**For the neo-Quineans**, the answer is *sometimes-ism about existence*. We need to paraphrase our ordinary language and scientific theories. While the exact rules for this paraphrasing are messy, but idea is to create a language that maximizes pragmatic virtues like simplicity, elegance, and explanatory power. It is from this idealized, paraphrased language that we are meant to read entities off the things being quantied over.

**For the neo-Carnapians**, the most plausible answer is *a general form of always-ism*: we can always freely read reality off our language. When another party, say John, uses a different yet equivalent language, there's nothing wrong with John, nor is there anything wrong with us. First, we can interpret both sides as speaking the truth, so there's no disagreement about facts. Second, from our point of view, there's nothing wrong with "John's way of thinking" because his resulting beliefs are also true. Here's why: if a sentence $S$ is true in language $L_{John}$​, then it is true for John to believe that $S$ *under the guise of* $L_{John}$. ==As Hirsch has argued multiple times, and even Sider seems to eventually agree (some citation), that there's nothing wrong with speaking and thinking in a language that is not isomorphic to the structure of reality.== By the same token, from John's point of view, there's nothing wrong with us either, whether in terms of truth or in terms of beliefs.

This "under the guise of" is motivated by the distinction between propositions and facts. (What I mean by 'proposition' here is the objects of our beliefs, and what I mean by 'fact' is the thing in the world that makes a sentence true.) For example, "Superman can fly" and "Clark Kent can fly" are the same fact, but they are different propositions: one might believe the former but not the latter. One way to explain this is to say that someone believes of $x$ *under the guise* of 'Superman', that $x$ can fly, while not believing $x$ under the guise of 'Clark Kent' that $x$ can fly.

By the same token, neo-Carnapians suggest we can see different linguistic frameworks as different "guises" for understanding the world. If there are equivalent languages can serve as equally good guises, there are many different ways to structure our knowledge of reality. Each of these guises constitutes genuine, true knowledge. This move allows neo-Carnapians to embrace a form of realism, distancing themselves from an anti-realist never-ism.[^1]

**For the neo-Aristotelians**, it seems they are holding *sometimes-ism about explanation or definition*, and *always-ism about existence*. Everything we can talk about trivially exists, but it might be derivative or idea-dependent. And the way we establish this kind of dependency is through the structure of definition or explanation (==citation to Fine's essence and modality, guide to ground, and Schaffer's work==).

The essential feature of definitions (and explanations) is that they are inherently *asymmetric*: nothing can define itself, and if $A$ is defined by $B$, then $B$ cannot be defined by $A$. However, this only applies to "real definitions," not "nominal definitions." For example, we may nominally define "A is on the left side of B" by "B is on the right side of A," and define "B is on the right side of A" by "A is on the left side of B." In fact, this kind of circularity probably appears occasionally when terms are defined in the dictionary.

Given this distinction, we cannot say that any definition in our language establishes fundamentality. Only the "real" ones count. The same principle applies to explanation. Although grounding relations are explanatory, they are not explanation itself. Explanation is famously context-sensitive. It depends on things such as what we're emphasizing, and what interests our audience. Grounding relations, by contrast, are intended to be worldly, objective, and context-independent. Since they are separate, only "real" explanation can establish fundamentality. This leads neo-Aristotelians to embrace *sometimes-ism* about explanation or definition.

Now we can clearly see the issue. Neo-Carnapians are arguing for a general form of *always-ism*, which would naturally includes the *always-ism about explanation or definition*. The pressure that the neo-Carnapian argument would put on the neo-Aristotelians' *sometimes-ism* is that, what makes some definition or explanation privileged so that they get to establish fundamentality, but the other doesn't? 

I will later defend sometimes-ism against always-ism, but for now I will put on the hat of neo-Carnapians and explain why the neo-Aristotelians did not give a satisfying answer.

Let me start with a way to establish the privilege of definition with a familiar concept: naturalness. This notion is famously introduced by Lewis (==Citation a new theory of universals==), but it was generally restricted to properties. But it was Sider who attempt to use this to establish fundamentality (==Citation writing the book of the world==). 

More natural, less natural
Essence
Built, building
Non-logical circle

[^1]: However, this approach immediately faces a problem. If I treat other people's languages as mere guises of reality, why shouldn't I treat my own language as a mere guise as well? Why do I privilege myself to read reality directly off my language, while denying others the same privilege with their languages? Moreover, if my language is also a guise, then it seems we would collapse back into the anti-realist's never-ism. In order to answer this, consider the following case. Let's construct a one-word-sentence language (OWS-language) where every sentence only has one unique symbol (or other unique representation, like sound. But I will use symbol in the following discussion for convenience). Every English sentence is a well-formed finite string composed of letters like English alphabet punctuation. (Assume our best linguists can figure out what count as a well-formed English sentence.) Then obviously, we can then construct a bijective function $f$ that mapping these English sentence string to a unique natural number. Then we give every natural number a unique symbol. Then have this one-word-sentence language. Crucially, these unique symbols carry no syntactic information about the original English structure. Now imagine a creature that genuinely _thinks_ in this one-word-sentence language, not secretly thinking in English. Suppose that after applying $f^{-1}$ to decode their utterances, we find complete agreement on truth values. They even agree with what decodes to "there are objects and properties." Now the problem is, this creature's way of thinking is inconceivable to human beings. Given that we have stipulated the way they think, it seems they cannot really have a grasp of objects and properties because they lack the representation to begin with. Yet, under translation, they do affirm that "there are objects and properties." It is only in this puzzling case, we have to appeal to the "guised reality" view because we cannot have any idea on what their take on reality is: They believe there are objects and properties *under the guise of* their one-word-sentence language. But our understanding of the reality is transparent, which means we normally do not need to appeal to the guise, until we found out there is misalignment between language and reality (like co-refering proper names).