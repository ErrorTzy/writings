---
documentclass: exam
title: Assignment
author: Scott Tang
mainfont: FreeSerif
CJKmainfont: Noto Serif CJK SC
mathfont: XITS Math
fontsize: 12pt
---

This paper is probably not a typical metaphysics paper. Although the main upshot is to establish fundamentality without magic, the kind of move I defend applies beyond metaphysics. At a very high level, the paper grapples with a central tension. On one hand, it seems all possible philosophical conclusions must ultimately rely on intuitive presuppositions. If so, then we cannot establish anything if we throw away all of our intuitions (or dispositions, sentiments, etc.). On the other hand, many of our intuitions seem shaky, unreliable, contingent and even contradictory with each other. The problem, then, is to figure out which part of our intuition cannot (or at least, should not) be thrown away. 

I frist argue this tension is somehow get ignored in the discussion of fundamentality. The consequence is that, the facts about fundamentality, though well-motivated, seems to be established by magic or wishful thinking. Then I argue for a principle that basically says, we cannot throw away our rational agency. And I spend the rest of the paper exploring what follows from it. Mostly, I use it to establish the directness of fundamentality without magic. But I also included a consequence in ethics.

The starting point of this paper comes from the following question: *How much reality should we read off our linguistic features?*

**Clarification of this question**: This way of asking the question immediately requires clarification. First, it seems to suggest linguistic idealism. It doesn't. Reality certainly does not depend on our language in any way. 

We might have ways to understand reality without language, perhaps through perception or mysterious experiences. But, this is not how metaphysics work. When we discuss reality in metaphysics, we inevitably rely on sophisticated language to explain reality. This has generated a long-standing worry in philosophy. Since medieval times, philosophers (e.g. nominalists) have been worrying that we might be confusing words with reality. They doubt whether metaphysics reveals reality or merely reveals some linguistic feature. Hence my question: when we try to talk about reality, which parts genuinely reflect how things are, and which parts are mere "shadows of language"?

Indeed, this question appears central to almost all metaphysical problems. For example, almost all natural languages have a subject-predicate structure. Should we then say, the world itself is constituted of objects and properties? Grammatically we have predicates like 'good' or 'bad'. Then should we read them off our language and say there are such properties in the world? The proposition $P$ may seem syntactically more primitive than $\neg \neg P$. Should we read this structure off our language and say the *fact* that $P$ is different, and in some sense more fundamental than the *fact* that $\neg \neg P$? Quantum physics describes the world in terms of wave functions. Should we then interpret that reality as just a bunch of waves (or maybe, a huge, holistic wave)?

It obvious that not every linguistic feature reveals reality. Take the names "Superman" and "Clark Kent." We don't think there are really two distinct entities out there connected by a relation named "identity". This is a non-trivial claim. Formally, one could construct a toy model $M = \langle D, I \rangle$ with $D = \{s, c\}$, $I(\text{'Superman'}) = s$, $I(\text{'Clark Kent'}) = c$ and $I(\text{'is'})= \{ \langle s,c \rangle, \langle c,s \rangle \}$. Such model would satisfy 'Superman is Clark Kent'.[^1] But intuitively we do not take such a model to capture reality because we think 'Superman' and 'Clark Kent' should refer to the same entity in the domain. 

Another thing needs to be clarified. What I mean by "language" includes inferential rules, or language-like mental process. In other words, "theory" and "language" are inter-changeable in this paper. And when I say someone is "using a language", I mean that person is also thinking in this language. For example, one is *not* using English if they are in fact thinking in German, then use Google Translate so that the utterance comes out in English.

This question is intended to bypass Amie Thomasson style argument that, adopting a language is easy, and thus ontology is easy. Ontology can't be that easy because it is not trivial to freely read reality off any language we like. And the explicit question of reality is intend to capture the heavyweight idea of what is "really" out there. For example, Sider's project about ontologese is best understood as, we should only read the (most fundamental) reality off the perfectly natural language, not unnatural languages that includes kinds like "incars" and "outcars". But there's no inherent problem for one to speak unnatural language as long as the unnatural language can express everything that can be expressed by ontologese.[^2]

The way I've framed the question, i.e. how much reality we should read off our linguistic features, is a bit different from the standard story told in metametaphysics. I think the standard narrative, which I'll lay out in a moment, tends to miss something important. I take the familiar story told by ==Schaffer (2009)==, probably the most-cited paper in the field, as the orthodox version (though I'll be telling a bit differently).

**The standard story** 

It goes something like this: contemporary metaphysics began with the Quine-Carnap debate. After Quine arguably won the debate, his approach to metaphysics prevailed. For Quine, the main task of metaphysics is to figure out what indispensably exists. Whether numbers or electrons exist depends on whether we must quantify over them in our best theories. This methodology was extended to other topics. Lewis, in some sense, can be seen as following the Quinean methodology: Since our best account of modality requires quantifying over possible worlds, possible worlds are real. From there, other concepts can be analyzed. Causation is explained by counterfactuals, which are analyzed in terms of possible worlds. Modality de re can be reduced to modality de dicto, plus some pragmatic, context-sensitive similarities. The takeaway is that most problems in metaphysics can be solved by first figuring out what exists and then maybe add a dash of pragmatics.

But then, the neo-Carnapians entered the scene. I believe the most important the idea from the neo-Carnapians is that, the meaning of "exists" can vary.[^3] According to this view, when different people debate about what exists, they are speaking different languages. If their languages are equivalent, then this is a mere verbal dispute.

Imagine one side speaks A-language and the other speaks B-language. For any sentence uttered by A-speakers, B-speakers will have their respective interpretation the sentence, vice versa. If the interpretation from each side always agrees on the truth value, then there's no disagreement other than disagreement on language: the other side is just expressing the fact in a different way. If that's the case, then many debates about what exists are merely verbal.

The implication here is serious. If metaphysics is founded on questions of existence, but quantifier variance shows that there are many equally good meanings of "existence" and the debates are merely verbal, then metaphysics risks becoming a largely trivial field of study.

Meanwhile the Neo-Aristotelians also come into play.[^5] They also attack on the neo-Quineans. They argued that even if we had a complete list of what exists, we'd still be missing something important: what is most fundamental, and what grounds what. Schaffer, for instance, argues that questions about existence are trivial. He says that of fictional characters and abstract objects trivially exist. The real, interesting question is about what grounds their existence. This shift in focus from existence to fundamentality has been the dominant trend in metaphysics for the past twenty years or so.

**The problem with the standard story**

Here's the problem. From the neo-Aristotelian perspective, this makes them look like the next logical step. In this view, the neo-Carnapians performed a useful, but purely *negative*, task by showing the flaws in the neo-Quinean focus on existence. With that groundwork laid, the neo-Aristotelians can then step in to offer a *positive* new project, turning the page on the neo-Quine-Carnap debate and building something new around concepts like grounding and fundamentality.

As a result of this framing, the standard story tends to sideline the neo-Carnapians. This isn't to say they're completely ignored, of course; people like Sider, Schaffer, and Bennett certainly take them seriously. Rather, the problem is that the standard story implies the neo-Carnapian critique is *only* about existence. And if that's the case, then the neo-Aristotelians, with their new focus, can safely disregard it. 

But this is surely *not* the case. The neo-Carnapian argument, on a high level, is about semantic variance. Therefore, it applies to any theory as long as the theory allows semantic variance. 

In order to see this more clearly, let's return to the question I framed at the start: *How much reality should we read off our linguistic features?*

**For the neo-Quineans**, the answer is *sometimes-ism about existence*. We can only sometimes read entities off the language we use. We need to paraphrase our ordinary language and scientific theories. While the exact rules for this paraphrasing are messy, but idea is to create a language that maximizes pragmatic virtues like simplicity, elegance, and explanatory power. It is from this idealized, paraphrased language that we are meant to read entities off the things being quantied over.

**For the neo-Carnapians**, the most plausible answer is *a general form of always-ism*: we can always freely read reality off the languages we use, as long as they are truth-functionally equivalent. When another party, say John, uses a different yet equivalent language, there's nothing wrong with John, nor is there anything wrong with us. First, we can interpret both sides as speaking the truth, so there's no disagreement about facts. Second, from our point of view, there's nothing wrong with "John's way of thinking" because his resulting beliefs are also true. Here's why: if a sentence $S$ is true in language $L_{John}$​, then it is true for John to believe that $S$ *under the guise of* $L_{John}$.[^6] By the same token, from John's point of view, there's nothing wrong with us either, whether in terms of truth or in terms of beliefs.[^7]

**For the neo-Aristotelians**, it seems they are holding *sometimes-ism about explanation or definition*, and *always-ism about existence*.[^11] Everything we can talk about trivially exists, but it might be derivative or idea-dependent. And the way we establish this kind of dependency is through the structure of definition or explanation (==citation to Fine's essence and modality, guide to ground, and Schaffer's work==).

The essential feature of definitions (and explanations) is that they are inherently *asymmetric*: nothing can define itself, and if $A$ is defined by $B$, then $B$ cannot be defined by $A$. However, this only applies to "real definitions," not "nominal definitions." For example, we may nominally define "A is on the left side of B" by "B is on the right side of A," and define "B is on the right side of A" by "A is on the left side of B." In fact, this kind of circularity probably appears occasionally when terms are defined in the dictionary.

Given this distinction, we cannot say that any definition in our language establishes fundamentality. Only the "real" ones count. The same principle applies to explanation. Although grounding relations are explanatory, they are not explanation itself. Explanation is (in)famously context-sensitive (==citation to van Fraassen, Kitcher==). It depends on things such as what we're emphasizing, and what interests our audience. Grounding relations, by contrast, are intended to be worldly, objective, and context-independent. Since they are separate, only "real" explanation can establish fundamentality. This leads neo-Aristotelians to embrace *sometimes-ism* about explanation or definition.

Now we can clearly see the issue. Neo-Carnapians are arguing for a general form of *always-ism*, which would naturally includes the *always-ism about explanation or definition*. The pressure that the neo-Carnapian argument would put on the neo-Aristotelians' *sometimes-ism* is that, what makes some definition or explanation privileged so that they get to establish fundamentality, but the other doesn't? 

I will later defend sometimes-ism against always-ism. In fact, the *general form of always-ism* is already under pressure. In the previous paragraph, I constructed an exotic toy model that satisfies "Superman is Clark Kent". According to always-ism, there is no problem with this model. Something already seems wrong. I later address this problem. For now I will put on the hat of neo-Carnapians and explain why the neo-Aristotelians did not give a satisfying answer.

**Naturalness**

Let me start with a way to establish a privileged definition using a familiar concept: *naturalness*. This notion was famously introduced by Lewis (==Citation a new theory of universals==), but his account was generally restricted to properties. It was Sider who attempted to use this concept to establish fundamentality (==Citation writing the book of the world==). Basically, Sider extends the notion of naturalness such that linguistic features beyond predicates (e.g., quantifiers, sentential connectives, sentential operators, predicate operators) can be evaluated by whether they carve the world at its joints or not.[^8] The linguistic features of the best language would then perfectly match the joints of reality. Given this extended understanding of naturalness, Sider contends that the most fundamental layer of the world is revealed by the structure of this best language. In this spirit, a "real explanation/definition" is the explanation/definition that only uses perfectly natural expressions.

But surely if the meaning of "naturalness" could vary between languages, then different languages could be considered "the best language" under different semantic interpretations of "naturalness." This is something Sider wants to avoid, because he argues that "naturalness" is supposed to be absolute or "objectively objective." The problem, then, is what makes the meaning of "naturalness" invariant across languages?

One way to defend this invariance is to appeal to reference magnetism: naturalness is itself natural, so the meaning of the term "naturalness" automatically gravitates to the most natural candidate meaning (==Sider p.23==). Sider stipulates that naturalness itself is perfectly natural (or, in his terminology, "structure itself is structural" ==p. 137==). Therefore, there is a unique answer to what the "reference magnet" is.

But this doesn't solve the problem. There is no contradiction in having two different languages, both of which agree on the sentence "naturalness itself is perfectly natural" while disagreeing on the extension of "naturalness." For example, in a mereological essentialist's language (ME-language), the ME-quantifier only ranges over simples, while in an ordinary language (OD-language), the OD-quantifier also ranges over composite objects. Assuming they both agree that naturalness itself is perfectly natural, there seems to be no contradiction in each side claiming its own quantifier to be perfectly natural, as long as they interpret "perfectly natural" differently. 

In addition, it is more plausible to take there to be no reference magnets. As Hirsch (==citations==) and Warren (==2023==) pointed out, language use completely trumps magnetism. Assume there are Martians seems as intelligent as we are. But they use '+' in a way that we need to interpret it as quus to make their utterance come out true. In this case, we should say the Martians are using '+' to mean quus. And in the cases of vagueness, like bald, where use cannot determine reference, we think it is just indeterminate. Therefore, the magnetic force is simply no where to be found.

The innitial motivation to posit reference magnetism is to explain why our '+' means plus, not quus, because it seems our *actual use* does not determine plus or quus, while there is a strong impluse to say the meaning of '+' is determined. But "actual use" might be a too narrow view about language use. Language use should include our disposition of use, and the disposition is enough to say '+' means plus. More will be said later, but for now I believe this is suffice to dismiss reference magnetism.

Let's return to the original problem: what makes the meaning of "naturalness" invariant across languages? More generally, when is any term's meaning fixed in this way?

In a trivial sense, of course, any symbol can be a mere placeholder; "naturalness" could be used to mean "hello," for instance. But this isn't the kind of meaningful variation we're concerned with here. There might be several ways to explain "invariance".[^10] But the relevant idea might help establish the invariance of "naturalness" here is that, the world can somehow teach us whether we are getting the right concept. If we are using a wrong concept, the world will correct us. For example, empirical facts tell us that changes of inertial perspective are, surprisingly, not sheer transformations. Then there are some privileged transformations, like Lorentz transformations, that objectively does better job at describing the world.

The parallel example used to support an "objectively objective naturalness" is Goodman's riddle of induction. The argument is that a concept like "grue" must be flawed because it leads to wrong conclusions, which suggests some concepts are objectively better than others. This is perhaps the strongest case for an objective standard of naturalness, but I believe it ultimately fails.

To recap the riddle: Since all emeralds observed before 2050 are green, they are also by definition "grue" (where grue means green and observed before 2050, or blue otherwise). Standard induction would tell us that the next emerald we see will also be grue. However, we intuitively know the next emerald will be green, meaning it will not be grue. Since the form of the induction seems right, the concept "grue" itself must be the problem.

But I think there is no problem for grue-speakers to do grue-induction. Let's consider two cases.

**Case 1**: In the first case, *we* assume that "being green" is an essential property of the kind "emerald." But why would *grue-speakers* accept this? By the same token, they might take "being grue" as the essence of an "emerald." If we showed them a green emerald in 2051, they would simply say, "*This isn't an emerald, because it's not grue.*" In that case, their induction is perfectly reliable: everything they call an "emerald" is, in fact, grue. Of course, this scenario is simple because it assumes the kind "emerald" is defined solely by its color. If so, the disagreement becomes a matter of a priori definition, not a failure of induction.

**Case 2**: So, let's consider a second, more realistic case. Assume both we and the grue-speakers agree that emeralds are defined by their chemical structure, let's call it ZYX, not their color. Through induction, our science might posit a law of nature that "*ZYX necessitates greenness.*" In grue-science, however, induction would lead to a law that "*ZYX necessitates grue-ness.*" When 2050 arrives, the grue-law will be falsified.

Does this mean our science is better because it uses "green" instead of "grue"? This doesn't seem right for two reasons.

First, Inductive failure is normal in science. For example, we might inductively conclude that all swans are white. The discovery of a black swan doesn't make the property "white" problematic; it just forces us to refine our theory.

Second, the argument is circular. Our science is better only if we assume that laws of nature don't involve strange properties like "grue." But why would the grue-speakers accept this? From their point of view, our properties are the strange ones.

Even if the true laws of nature do involve "green" instead of "grue," the grue-speakers aren't at a theoretical disadvantage. After their initial law is falsified, they can simply revise their theory. They can still define "green" using their own concepts and eventually arrive at the same scientific law we do.

One might argue that the laws of nature themselves specify which properties are natural. If these laws are objective, then naturalness would be too. So, if a law of nature shows that all emeralds are green, we could conclude that "grue" is metaphysically defective.

But this critique only works if we already know the true law is "emeralds are green." Given that we haven't reached 2050 yet, how can we conclude that the law is "emeralds are green" and not "emeralds are grue"? Moreover, we could just invent a new concept, "grue*", defined as "green if observed before 2051, or blue otherwise." In fact, for any set of observations, there are infinitely many grue-like concepts that are consistent with the data. What reason, then, do we have to single out "emeralds are green" as the one true law of nature? Surely there is no problem, according to Bayesian principles, to adopt a higher credence for green-laws based on prior distribution. And this is enough for confirmation. But there is no theoretical reason to single out greenness as a metaphysically privileged concept.

**Grounding and Essence**

Maybe "naturalness" is already too niche. Indeed, the most orthodoxical way to establish fundamentality is through concepts like grounding or essence. For example, the most fundamental layer is ungrounded (i.e. independent), and everything is either the most fundamental, or is grounded by the most fundamentals (i.e. compleness). In my terminology, $P$ "really" explains $Q$ iff $P$ is grounded by $Q$. In other words, the *sometimes-ism* about explanation is explained by grounding 

The concept of grounding, however, notoriously lacks consensus. What I here mean by grounding means what is referred to as "small-g", or in Bennett's term, "building". But before getting further into this, I wish to go into another concept, i.e. essence.

The approach to establish fundamentality through essence is largely due to Kit Fine's series of work (==Fine citation: essence and modality; senses of essence; Ontological Dependence and The logic of essence==). Of course, Fine perfer to treat ontological dependency as primitive and it is a part of the axioms. But Fine acknowledge that this is merely a technical choice, and we can define ontological dependency by essence: $x$ depends on $y$ when there is some property $\phi$ (that does not mention $y$) such that in virtue of $x$'s nature it's true that $y$ has $\phi$, but in virtue of $x$'s nature it's not true that everything has $\phi$. Formally, according to Fine we can choose to define $x \ge y =_{df} \Box_x(y=y)$ along with other axioms in order to capture the informal definition. 

Here I don't want to focus on the discussions about Fine' derivation rules. And I acknowledge that, essence is an intuitive concept such that de re modality should be built upon, not the other way around. But instead my question is a semantic one: why should we take essence as a feature of reality? Again, we can be sure it is a feature of reality if (1) there is another language that attributes essence differently, and (2) we would have good reasons to think their attribution is wrong (e.g. they yield )



1. strange grounding structure
2. debunking grounding intuition

Non-logical circle




- **The principle of sanity**: For someone who is capable of philosophical reflection, it is impossible to genuinely believe oneself to not be a rational agent.

**Clarification for this principle**: This principle also applies to acceptance (i.e. It is impossible for someone to accept oneself to not be a rational agent), but I will focus on belief in the rest of the paper unless specified otherwise. Anyway, the upshot is, it is impossible for us to really adopt a theory that eliminates rational agency.

Here, "philosophical reflection" roughly refers to activities such as examining and revising one's beliefs, analyzing arguments, and choosing between competing theories. The condition "for a person capable of philosophical reflection" is to rule out certain exotic counterexamples. For instance, someone who has been so thoroughly brainwashed that their only possible belief is "I am not a rational agent" would not qualify as a counterexample. I assume all readers who have already made it here are automatically capable of philsosophical reflection. Similarly, saying "genuinely believe" is to rule out counterexamples from self-deception.

What I mean by "rational" here is a minimal sense of means-end coherence. For example, someone who wills their hand to rise but finds their leg going up instead would lack this coherence. Thus, even if this could somehow be a case of agency, it wouldn't be rational agency in the relevant sense.

The precise meaning of "rational agency", of course, is highly controversial and open to multiple acceptable interpretations. Consequently, this principle will have different variants depending on how one chooses to define the term. However, I contend that the *principle of sanity* is plausible under most, if not all, commonsensical interpretations.

For current purpose, it will suffice by adopting a minimal account of rational agency as *epistemic agency*. But I will add more to "rational agency" later in this paper. What I mean by "epistemic agency" here is not the kind of agency resisted by doxastic involuntarists. According to doxastic involuntarists, *direct* voluntary control over belief is not possible for us. But here, I use "epistemic agency" to refer to any sort of control over our beliefs, no matter how indirect. For example, we have the ability to choose to re-examine our beliefs and investigate new evidence. Doxastic involuntarists, like ==Hieronymi 2008==, also acknowledge that we possess this kind of indirect control. Therefore, it is uncontroversial that we have epistemic agency in the intended sense.

**Reasons for this principle**: This is more or less an axiom in this paper that I take to be self-evident. But I will still try to give some defense. 

First, implicitly, this is already a widely accepted principle. Aristotle appears to adopt this principle in Chapter 9 of _De Interpretatione_. There, he rejects the principle of bivalence due to our deliberation and action. He argues that, deliberation and action requires that, propositions about the future must be open (19a10). Then they cannot have a truth value now (19a26). Therefore the principle of bivalence is false. However, Aristotle's argument seems to epistemic instead of metaphysical. When he writes that "what will be has an origin both in deliberation and in action" (19a6-9), the plausible interpretation is that our *beliefs* about the future originate from these rational activities, not the future state of affairs itself. If so, his argument is best understood as follows: it is impossible for us to genuinely *believe* that the future is predetermined while simultaneously viewing ourselves as rational agents who deliberate. Therefore, by *the principle of sanity*, we cannot adopt the principle of bivalence.

There are also more contemporary cases.People seems to reject epiphenomenalism largely due to the reason that, if there's no mental causation, then it seems we wouldn't have any agency, which is insane. And I will argue later that, the motivation of a widely held metasemantics principle, *the Principle of Charity*, actually comes from of a stronger version of *the Principle of Sanity*. Therefore, in fact people have been implicitly using this principle.

Nonetheless, I will also try to sketch a direct defense. If the principle were false, then it would be possible for a creature to engage in philosophical reflection without believing itself to have rational agency. But philosophical reflection inherently requires making inferences and utilizing abstract concepts. Let's assume, as is widely held, that such complex thought requires language (or at least some language-like mentalese). Then, I argue in the following paragraph that using language for this purpose necessitates rational agency. Therefore this creature is impossible.

To use language requires intentionality. For example, a dinosaur that accidentally scratches the shape of the symbol "water" into the ground is not using language, because it does not use the symbol intentionally to represent something. Therefore, intentionality is necessary for language use. But to use representation intentionally for philosophical reflection just is to exercise the very sort of indirect, agential control over one's beliefs by potentially revising what one holds to be true. And we must be able, at least to some extent, to be aware of our own intentions. If we are aware of our intentions to some extent, we believe that we have such intentions. Thus, if we use language to engage in philosophical reflection, we must believe in epistemic agency.

I do not take this to be an invincible argument. Perhaps with some heavy argument, one may claim we can build a "philosophy machine" that can reflect on arguments and produce a philosophy paper while being completely non-agential. However, I believe it is quite obvious that rejecting the principle of sanity, plainly, is to be insane. Even if such a "philosophy machine" is possible, I still think no person should reject this principle, simply because we should not be insane.[^9]

There are obvious consequence for adopting this principle. Together with the following innocent principle that:

- **Ought Implies Can**: If it is impossible for us to believe that P, then it is not the case that we ought to believe that P.

It follows that *the Principle of Sanity* is incompatible with the traditional account of rationality: A belief is rational iff the reason to believe is truth-tracking. This is because the principle of sanity commits us to a belief we must hold (that we are rational agents), regardless of the evidence. Assume our epistemic norm is to hold only true beliefs, and scientists tell us that rational agency is just an illusion, then we would be obligated to believe that we are not rational agents. But according to the principle that *Ought Implies Can*, there is no such obligation.

Then immediately, one might object that if epistemic norms must be truth-tracking, then we should rationally reject *the Principle of Sanity* itself. However, what does it mean to "rationally reject" a principle? If doing so is an act of philosophical reflection, then, as argued earlier, the very act requires us to presuppose our own epistemic agency. Therefore, any attempt to "rationally reject" *the Principle of Sanity* is self-defeating, as the act of rejection presupposes the very rational agency the principle commands us to accept.

There is also an auxiliary argument that help me establish the metaphysical argument that I want to establish. According to the neo-Quinean view on metametaphysics, choosing between empirically-equivalent theories is a matter of comparing their pragmatic virtues. And usually, they were considering theoretic simplicity, elegance, etc. But what how could these pragmatic virtues more valuable than our rational agency?

Direct consequence of the Sanity Principle: Cannot eliminate first person and causation

Indirect consequence of the Sanity Principle: establishing fundamentality without magic

Beyond metaphysics: trusting friends against evidence

Conclusion

[^1]: Needless to say, in a complete model for English language, many other vocabularies need different interpretations.
[^2]: Hirsch has written a lot on this, but I think the best way to capture Hirsch's idea is to raise the following question: What's metaphysically good about having only one unique word to refer to nature's joint, instead of using longer phrases?
[^3]: I'm focusing on quantifier variance because I believe it's the most plausible and basic form of the neo-Carnapian position. ==Thomasson (2015 p. 70)== herself thinks her easy ontology doesn't depend on quantifier variance, but this is surely mistaken. Her project relies on the triviality of changing the extension of the predicate "exists". But this surely changes the meaning of the quantifier.
[^5]: Surely this paper is not intended to become the zoology of metametaphysics, so these labels may not be precise. What I mean by neo-Aristotelians is basically the fans of fundamentality. For example, Sider counts as a neo-Aristotelian in my sense. Though Sider is usually considered as a neo-Lewisian, which is closer to neo-Quinean. But the label is not important anyway.
[^6]: As Hirsch has argued multiple times ==citation==, and even Sider seems to eventually agree (==some citation==), that there's nothing wrong with speaking and thinking in a language that is not isomorphic to the structure of reality
[^7]: This "under the guise of" is motivated by the distinction between propositions and facts. (What I mean by 'proposition' here is the objects of our beliefs, and what I mean by 'fact' is the thing in the world that makes a sentence true.) For example, "Superman can fly" and "Clark Kent can fly" are the same fact, but they are different propositions: one might believe the former but not the latter. One way to explain this is to say that someone believes of $x$ *under the guise* of 'Superman', that $x$ can fly, while not believing $x$ under the guise of 'Clark Kent' that $x$ can fly. <br> By the same token, neo-Carnapians suggest we can see different linguistic frameworks as different "guises" for understanding the world. If there are equivalent languages can serve as equally good guises, there are many different ways to structure our knowledge of reality. Each of these guises constitutes genuine, true knowledge. This move allows neo-Carnapians to embrace a form of lightweight realism, distancing themselves from an anti-realist never-ism. <br> However, this approach immediately faces a challenge. If I treat other people's languages as mere guises of reality, why shouldn't I treat my own language as a mere guise as well? Moreover, if my language is also a guise, then it seems we would collapse back into the anti-realist's never-ism. In order to answer this challenge, consider the following case. First, let's establish that the set of all well-formed English sentences, taken as finite strings, is countable. We can have a bijective function $f$ that maps every unique English sentence to a unique natural number. From this, we can construct a One-Word-Sentence language (OWS-language for short). In this language, each natural number (and thus each corresponding English sentence) is represented by a single, unique symbol (e.g., '∇', '§', 'Д'). Crucially, these symbols carry no internal syntactic information that mirrors the structure of the original English sentences. Now, imagine a creature that genuinely thinks in this OWS-language, not one that is secretly translating from English. Suppose that when we apply the inverse function, $f^{−1}$, to decode their one-word utterances, we find they agree with us on the truth value of every proposition. They even affirm the OWS-symbol that decodes to "There are objects and properties." Here is the problem. This creature's way of thinking is inconceivable to us. Given we stipulated that they think in OWS, it seems they cannot grasp the concepts of objects and properties. Yet, their statements, once translated, shows they think there are objects and properties. It is in cases like this that we must appeal to the "guised reality" view. We are forced to say that they believe there are objects and properties under the guise of their OWS-language, precisely because there is no way to understand their take on reality. Or in other words, we are *unable* to read reality off this OWS language. In contrast, our own understanding is transparent. We do not take of our language as a "guise" because it is normally a transparent *presentation of the reality*, not representation. We only appeal to "guise" in specific cases of misalignment, such as with co-referring proper names like 'Superman' and 'Clark Kent.'
[^8]: In fact Sider tend to drop the term "naturalness" to favor the term "joint-carving" or "structural" for the extended meaning of "naturalness". But let me stick to "naturalness" here.
[^9]: In other words, I am in fact suggesting two different principles. The stronger version is what I explicitly laid down and inclined to stand with. But even if one somehow resisted it, my conclusion can still be established by the weaker version, i.e. if we are capable of philosophical reflection, then we should not believe we are not rational agents.
[^10]: One possible approach is to define the essential meaning of a term by its introduction and elimination rules (IE-rules), that is, by its functional role in language. For a term to count as a quantifier, for example, it must obey the IE-rules for quantifiers. However, the full meaning of a quantifier also depends on its domain, and the IE-rules don't fix this. Therefore, the meaning of a quantifier can still vary as its domain varies. This approach faces several problems. First, this form of essentialism about meaning seems arbitrary. Why should IE-rules be the only thing that constitutes a term's essential meaning? For example, we might say in some sense 'quus' is a variation of 'plus', not a completely unrelated concept like 'Hello'. But they have different IE-rules. Second, for non-logical terms, the IE-rules themselves are usually formulated using terms that can vary. Third, and most importantly, even if we accept this IE-rules essentialism, it would not help fix "naturalness". It leads to a specific conclusion: a term's meaning is invariant if its meaning is exhausted by its IE-rules. For example, a logical conventionalist might say $\land$'s meaning entirely determined its IE-rules. Then according to IE-rules essentialism, $\land$ is invariant. However, Sider clearly intends "naturalness" to be more than just a conventional, syntactic symbol. Therefore, this strategy for securing semantic invariance is not a viable option for his project.
[^11]: This is probably not the orthodoxical formulation. The orthodoxical formulation is, we distinguish absolute fundamentality and relative fundamentality. For absolutely fundamentality, we usually appeal to concepts like completeness, dependency, indispensability or naturalness. But when asked which set of facts are complete, or independent, or indispensable, or perfectly natural, we appeal to virtues like power of explanation or definitional simplicity. Therefore, ultimately we decide what's abosolutely fundamental based on explanation or definition. I have not seen how could this be done otherwise. This also applies to relative fundamentality.